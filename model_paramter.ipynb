{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa59c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.13 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bbb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\r\n",
      "------------------- ---------\r\n",
      "appnope             0.1.2\r\n",
      "argon2-cffi         20.1.0\r\n",
      "async-generator     1.10\r\n",
      "attrs               21.4.0\r\n",
      "backcall            0.2.0\r\n",
      "bleach              4.1.0\r\n",
      "certifi             2021.5.30\r\n",
      "cffi                1.14.6\r\n",
      "decorator           5.1.1\r\n",
      "defusedxml          0.7.1\r\n",
      "entrypoints         0.3\r\n",
      "ipykernel           5.3.4\r\n",
      "ipython             7.16.1\r\n",
      "ipython-genutils    0.2.0\r\n",
      "jedi                0.17.0\r\n",
      "Jinja2              3.0.3\r\n",
      "jsonschema          3.0.2\r\n",
      "jupyter-client      7.1.2\r\n",
      "jupyter-core        4.8.1\r\n",
      "jupyterlab-pygments 0.1.2\r\n",
      "MarkupSafe          2.0.1\r\n",
      "mistune             0.8.4\r\n",
      "nbclient            0.5.3\r\n",
      "nbconvert           6.0.7\r\n",
      "nbformat            5.1.3\r\n",
      "nest-asyncio        1.5.1\r\n",
      "notebook            6.4.3\r\n",
      "packaging           21.3\r\n",
      "pandocfilters       1.5.0\r\n",
      "parso               0.8.3\r\n",
      "pexpect             4.8.0\r\n",
      "pickleshare         0.7.5\r\n",
      "pip                 21.2.2\r\n",
      "prometheus-client   0.13.1\r\n",
      "prompt-toolkit      3.0.20\r\n",
      "ptyprocess          0.7.0\r\n",
      "pycparser           2.21\r\n",
      "Pygments            2.11.2\r\n",
      "pyparsing           3.0.4\r\n",
      "pyrsistent          0.17.3\r\n",
      "python-dateutil     2.8.2\r\n",
      "pyzmq               22.2.1\r\n",
      "Send2Trash          1.8.0\r\n",
      "setuptools          58.0.4\r\n",
      "six                 1.16.0\r\n",
      "terminado           0.9.4\r\n",
      "testpath            0.5.0\r\n",
      "tornado             6.1\r\n",
      "traitlets           4.3.3\r\n",
      "wcwidth             0.2.5\r\n",
      "webencodings        0.5.1\r\n",
      "wheel               0.37.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7c82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 86.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[K     |████████████████████████████████| 498 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5 pytz-2022.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877aa40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-macosx_10_11_x86_64.whl (198.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 198.9 MB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 38.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.48.2-cp36-cp36m-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 60.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from tensorflow) (0.37.1)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 76.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-macosx_10_9_x86_64.whl (979 kB)\n",
      "\u001b[K     |████████████████████████████████| 979 kB 50.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 32.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 27.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 7.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.0.4)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "\u001b[K     |████████████████████████████████| 289 kB 46.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 83.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 530 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 83.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 79.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: clang, termcolor, wrapt\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=954d2e6ff47225b5bf91a43c6f9b74eac1a75c180f3be7c104c0dd9274c8b8a3\n",
      "  Stored in directory: /Users/kimhyunjo/Library/Caches/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=3859e8e4a58ed5856df42b1ac61c15711d10679d651d6d0a4996bce85cdf9afe\n",
      "  Stored in directory: /Users/kimhyunjo/Library/Caches/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-macosx_10_9_x86_64.whl size=32472 sha256=ee66b56fcd301f08fb588ce9e3eef9af964bbc6438279374c7a16d57be800cc1\n",
      "  Stored in directory: /Users/kimhyunjo/Library/Caches/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built clang termcolor wrapt\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, dataclasses, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, cached-property, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 charset-normalizer-2.0.12 clang-5.0 dataclasses-0.8 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 idna-3.4 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.7 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 six-1.15.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.12 werkzeug-2.0.3 wrapt-1.12.1 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed2eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86a5c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "output_softmax (Dense)       (None, 20, 10)            20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (20, 1), name = 'input')\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'output_softmax')(inputs)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753dc21c",
   "metadata": {},
   "source": [
    "## Hidden Layer 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46f082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 232\n",
      "Trainable params: 232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Input_size = 20\n",
    "inputs = tf.keras.layers.Input(shape = Input_size, name = 'input')\n",
    "hidden1 = tf.keras.layers.Dense(units = 10 , activation = 'relu', name = 'hidden1')(inputs)\n",
    "# hidden1 = tf.keras.layers.Dense(units = 10 , activation = tf.nn.relu, name = 'hidden1')(inputs)\n",
    "outputs = tf.keras.layers.Dense(units = 2, activation = 'softmax', name = 'output')(hidden1)\n",
    "# outputs = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax, name = 'output')(hidden1)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "052d45b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 232\n",
      "Trainable params: 232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 20\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE, name = 'input')\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2, name = 'dropout')(inputs)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = 'relu', name = 'hidden')(dropout)\n",
    "outputs = tf.keras.layers.Dense(units = 2, activation = 'softmax', name = 'output')(hidden)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17d261",
   "metadata": {},
   "source": [
    "## 1D conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71872c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 20, 10)            40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(filters = 10,\n",
    "                             kernel_size = 3, padding = 'same',\n",
    "                             activation = 'relu')(inputs)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs = inputs, outputs = conv)\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25a236cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"funtionAPI\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 20, 1)]           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 1)             0         \n",
      "_________________________________________________________________\n",
      "Conv (Conv1D)                (None, 20, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 6, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (20, 1), name = 'input')\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2, name = 'dropout')(inputs)\n",
    "conv = tf.keras.layers.Conv1D(filters = 10,\n",
    "                             kernel_size = 3,\n",
    "                             padding = 'same',\n",
    "                             activation = 'relu',\n",
    "                             name = 'Conv')(dropout)\n",
    "\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3)(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = 'relu', name = 'hidden')(flatten)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'outputs')(hidden)\n",
    "\n",
    "model_functionAPI = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'funtionAPI')\n",
    "\n",
    "model_functionAPI.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a955d",
   "metadata": {},
   "source": [
    "## Model 구축 <1>\n",
    "### sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01e1b057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequentail_API\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense1 (Dense)               (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Outputs (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name = 'Sequentail_API')\n",
    "model.add(tf.keras.layers.Input(shape = (32, ), name = 'input'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'Dense1'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'Dense2'))\n",
    "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'Outputs'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961ad91",
   "metadata": {},
   "source": [
    "## Model 구축 <2>\n",
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5030a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequentail_API\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense1 (Dense)               (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Outputs (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (32,), name = 'input')\n",
    "Dense1 = tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'dense1')(inputs)\n",
    "Dense2 = tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'dense2')(Dense1)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'outputs')(Dense2)\n",
    "\n",
    "model_function = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'Functional_API')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b720d",
   "metadata": {},
   "source": [
    "## Model 구축 <3>\n",
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "502d5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customlayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, hidden1, hidden2, output_layer) :\n",
    "        super(Customlayer, self).__init__()\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.output_layer = output_layer\n",
    "        \n",
    "    def build(self, inputs) :\n",
    "        self.dense_layer1 = tf.keras.layers.Dense(units = self.hidden1, activation = 'relu', name = 'Dense1')\n",
    "        self.dense_layer2 = tf.keras.layers.Dense(units = self.hidden2, activation = 'relu', name = 'Dense2')\n",
    "        self.output_layers = tf.keras.layers.Dense(units = self.output_layer, activation = 'softmax', name = 'output')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "        \n",
    "        return self.output_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12e752d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Custom_layer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "customlayer (Customlayer)    (None, 10)                6922      \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name = 'Custom_layer')\n",
    "model.add(tf.keras.layers.Input(shape = (32, )))\n",
    "model.add(Customlayer(64, 64, 10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c466e",
   "metadata": {},
   "source": [
    "## Model 구축 <4>\n",
    "### Subclassing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ba7c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model) :\n",
    "    def __init__(self, hidden1, hidden2, output_layers) :\n",
    "        super(MyModel, self).__init__(name = 'MyModel')\n",
    "        self.dense1 = tf.keras.layers.Dense(units = hidden1, activation = 'relu', name = 'dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(units = hidden2, activation = 'relu', name = 'dense2')\n",
    "        self.output_layer = tf.keras.layers.Dense(units = output_layers, activation = 'softmax', name = 'output_layer')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub = MyModel(64, 64, 10)\n",
    "\n",
    "model_sub.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# train data 를 넣어야 한다\n",
    "model_sub.fit(train_input, train_target, epochs = 20, batch_size = 64)\n",
    "\n",
    "model_sub.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
