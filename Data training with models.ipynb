{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b281db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d531f",
   "metadata": {},
   "source": [
    "## Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e461f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_API\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name = 'Sequential_API')\n",
    "model.add(tf.keras.layers.Input(shape = (32, ), name = 'input'))\n",
    "model.add(tf.keras.layers.Dense(units = 32, activation = 'relu', name = 'dense1'))\n",
    "model.add(tf.keras.layers.Dense(units = 16, activation = 'relu', name = 'dense2'))\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid', name = 'output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529690d",
   "metadata": {},
   "source": [
    "## Functional 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc85e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Funtional_API\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (32, ), name = 'input')\n",
    "hidden1 = tf.keras.layers.Dense(units = 32, activation = 'relu', name = 'dense1')(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(units = 16, activation = 'relu', name = 'dense2')(hidden1)\n",
    "outputs = tf.keras.layers.Dense(units = 1, activation = 'sigmoid', name = 'outputs')(hidden2)\n",
    "\n",
    "model_functional = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'Funtional_API')\n",
    "\n",
    "model_functional.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6cef19",
   "metadata": {},
   "source": [
    "## Subclassing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ce7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(tf.keras.Model) :\n",
    "    def __init__(self, hidden1, hidden2, outputs) :\n",
    "        super(Mymodel, self).__init__(name = 'Subclassing')\n",
    "        self.dense1 = tf.keras.layers.Dense(units = hidden1, activation = 'relu', name = 'dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(units = hidden2, activation = 'relu', name = 'dense2')\n",
    "        self.outputs = tf.keras.layers.Dense(units = outputs, activation = 'sigmoid', name = 'output_sigmoid')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.outputs(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f08a2",
   "metadata": {},
   "source": [
    "### 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6357b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel_sub = Mymodel(32, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c218ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Subclassing\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               multiple                  528       \n",
      "_________________________________________________________________\n",
      "output_sigmoid (Dense)       multiple                  17        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel_sub.build(input_shape = (100, 32, ))\n",
    "mymodel_sub.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1960087",
   "metadata": {},
   "source": [
    "### 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a92097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('./data_set/pima-indians-diabetes.csv', delimiter = ',')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1f068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0 : -1]\n",
    "Y = data[ : , -1]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e8582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mymodel(12, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcf41d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = './model_save/best_model.hdf5',\n",
    "                                               moitor = 'val_loss',\n",
    "                                               verbose = 1,\n",
    "                                               save_best_only = True,\n",
    "                                               save_weights_only = True)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c24580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 16ms/step - loss: 5.5491 - acc: 0.6515 - val_loss: 4.6832 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.68319, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3.5351 - acc: 0.6124 - val_loss: 3.3376 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.68319 to 3.33758, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.6909 - acc: 0.5945 - val_loss: 2.6232 - val_acc: 0.5649\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.33758 to 2.62320, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2.1765 - acc: 0.5733 - val_loss: 2.0874 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.62320 to 2.08739, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.9165 - acc: 0.5879 - val_loss: 1.8777 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.08739 to 1.87765, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.7141 - acc: 0.5847 - val_loss: 1.7230 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.87765 to 1.72299, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.5418 - acc: 0.5749 - val_loss: 1.6035 - val_acc: 0.5649\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.72299 to 1.60350, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.4069 - acc: 0.5912 - val_loss: 1.4791 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.60350 to 1.47906, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3151 - acc: 0.5993 - val_loss: 1.3732 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.47906 to 1.37321, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.2361 - acc: 0.5961 - val_loss: 1.2753 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.37321 to 1.27528, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.1506 - acc: 0.6156 - val_loss: 1.1754 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27528 to 1.17536, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0821 - acc: 0.6303 - val_loss: 1.0873 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.17536 to 1.08729, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.0035 - acc: 0.6336 - val_loss: 1.0186 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.08729 to 1.01863, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9448 - acc: 0.6450 - val_loss: 0.9748 - val_acc: 0.6494\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.01863 to 0.97479, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9112 - acc: 0.6401 - val_loss: 0.9599 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.97479 to 0.95992, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8865 - acc: 0.6270 - val_loss: 0.9221 - val_acc: 0.6299\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.95992 to 0.92208, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8552 - acc: 0.6319 - val_loss: 0.8903 - val_acc: 0.5779\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.92208 to 0.89026, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8346 - acc: 0.6189 - val_loss: 0.8583 - val_acc: 0.6039\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.89026 to 0.85834, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.6417 - val_loss: 0.8592 - val_acc: 0.5649\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.85834\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8065 - acc: 0.6156 - val_loss: 0.8497 - val_acc: 0.5649\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.85834 to 0.84970, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7932 - acc: 0.6140 - val_loss: 0.8072 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.84970 to 0.80722, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7939 - acc: 0.6564 - val_loss: 0.8031 - val_acc: 0.5779\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.80722 to 0.80313, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7807 - acc: 0.6156 - val_loss: 0.8044 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80313\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7665 - acc: 0.6352 - val_loss: 0.7801 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.80313 to 0.78007, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7590 - acc: 0.6336 - val_loss: 0.7894 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.78007\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7594 - acc: 0.6401 - val_loss: 0.7666 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.78007 to 0.76659, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7474 - acc: 0.6547 - val_loss: 0.7832 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.76659\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7399 - acc: 0.6270 - val_loss: 0.7506 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.76659 to 0.75057, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7393 - acc: 0.6417 - val_loss: 0.7559 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.75057\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7329 - acc: 0.6336 - val_loss: 0.7746 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.75057\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7203 - acc: 0.6612 - val_loss: 0.7380 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.75057 to 0.73802, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7396 - acc: 0.6319 - val_loss: 0.7273 - val_acc: 0.6299\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.73802 to 0.72725, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7189 - acc: 0.6629 - val_loss: 0.7408 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.72725\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7067 - acc: 0.6368 - val_loss: 0.7341 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.72725\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.6531 - val_loss: 0.7143 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.72725 to 0.71433, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 0.6482 - val_loss: 0.7255 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.71433\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.6531 - val_loss: 0.7250 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.71433\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.6417 - val_loss: 0.7023 - val_acc: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 0.71433 to 0.70229, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6836 - acc: 0.6661 - val_loss: 0.7097 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.70229\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.6564 - val_loss: 0.6936 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.70229 to 0.69360, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6750 - acc: 0.6645 - val_loss: 0.7090 - val_acc: 0.6494\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.69360\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6663 - acc: 0.6678 - val_loss: 0.7117 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.69360\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6833 - acc: 0.6645 - val_loss: 0.6888 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.69360 to 0.68876, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6610 - acc: 0.6547 - val_loss: 0.6994 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.68876\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6686 - acc: 0.6694 - val_loss: 0.6807 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.68876 to 0.68065, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6572 - acc: 0.6547 - val_loss: 0.6942 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.68065\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6508 - acc: 0.6743 - val_loss: 0.6788 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.68065 to 0.67885, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6519 - acc: 0.6629 - val_loss: 0.6701 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.67885 to 0.67011, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6552 - acc: 0.6792 - val_loss: 0.6770 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.67011\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6509 - acc: 0.6808 - val_loss: 0.6747 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.67011\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6449 - acc: 0.6824 - val_loss: 0.6831 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.67011\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6477 - acc: 0.6612 - val_loss: 0.6668 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.67011 to 0.66679, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6356 - acc: 0.6873 - val_loss: 0.6674 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.66679\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6367 - acc: 0.6726 - val_loss: 0.6602 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.66679 to 0.66022, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6305 - acc: 0.6726 - val_loss: 0.6626 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.66022\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6278 - acc: 0.6808 - val_loss: 0.6533 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.66022 to 0.65333, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6236 - acc: 0.6808 - val_loss: 0.6575 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.65333\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6305 - acc: 0.6824 - val_loss: 0.6558 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.65333\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6906 - val_loss: 0.6546 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.65333\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6267 - acc: 0.6922 - val_loss: 0.6574 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.65333\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6264 - acc: 0.6726 - val_loss: 0.6479 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.65333 to 0.64792, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6227 - acc: 0.6857 - val_loss: 0.6547 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.64792\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6216 - acc: 0.7003 - val_loss: 0.6426 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.64792 to 0.64258, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6128 - acc: 0.6873 - val_loss: 0.6509 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.64258\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6079 - acc: 0.6889 - val_loss: 0.6427 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.64258\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6018 - acc: 0.7020 - val_loss: 0.6483 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.64258\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5998 - acc: 0.7003 - val_loss: 0.6421 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.64258 to 0.64214, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6059 - acc: 0.6824 - val_loss: 0.6371 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.64214 to 0.63712, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6117 - acc: 0.7134 - val_loss: 0.6475 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.63712\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6064 - acc: 0.6889 - val_loss: 0.6427 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.63712\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5994 - acc: 0.7150 - val_loss: 0.6437 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.63712\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6026 - acc: 0.7003 - val_loss: 0.6381 - val_acc: 0.6753\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.63712\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5986 - acc: 0.6906 - val_loss: 0.6336 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.63712 to 0.63359, saving model to ./model_save/best_model.hdf5\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5913 - acc: 0.7166 - val_loss: 0.6437 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.63359\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5975 - acc: 0.6873 - val_loss: 0.6452 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.63359\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5986 - acc: 0.7166 - val_loss: 0.6433 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.63359\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5955 - acc: 0.6954 - val_loss: 0.6373 - val_acc: 0.6948\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.63359\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5869 - acc: 0.7182 - val_loss: 0.6428 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.63359\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5897 - acc: 0.7101 - val_loss: 0.6419 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.63359\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5841 - acc: 0.7068 - val_loss: 0.6392 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.63359\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5808 - acc: 0.7199 - val_loss: 0.6358 - val_acc: 0.6948\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.63359\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5809 - acc: 0.7134 - val_loss: 0.6343 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.63359\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5824 - acc: 0.7231 - val_loss: 0.6485 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.63359\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "history = model.fit(X, Y, epochs = 100, batch_size = 70, validation_split = 0.2, callbacks = [checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defac55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], 'r', label = 'val_loss')\n",
    "plt.plot(history.history['loss'], 'b', label = 'train_loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df046cf",
   "metadata": {},
   "source": [
    "# 자연어 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d31b6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진자 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "targets = [[1], [0], [1], [1], [0], [1]] # 1 = positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501612c",
   "metadata": {},
   "source": [
    "### tokenizer 는 단어의 총 갯수만큼 번호를 부여 한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffa035ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진자': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88afbf",
   "metadata": {},
   "source": [
    "### 문장의 길이가 4로 동일한 경우\n",
    "현업에서는 이런경우는 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f01b48be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['너 오늘 이뻐 보인다', '나는 오늘 기분이 더러워', '끝내주는데, 좋은 일이 있나봐', '나 좋은 일이 생겼어', '아 오늘 진자 짜증나', '환상적인데, 정말 좋은거 같아']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4,  1,  5,  6],\n",
       "       [ 7,  1,  8,  9],\n",
       "       [10,  2,  3, 11],\n",
       "       [12,  2,  3, 13],\n",
       "       [14,  1, 15, 16],\n",
       "       [17, 18, 19, 20]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "input_sequence = np.array(sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "print(samples)\n",
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71ca3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfaa61",
   "metadata": {},
   "source": [
    "### Embedding hidden 노드의 구조\n",
    "128 * 21 의 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e923468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 128)            2688      \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "Outputs (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name = 'Sequential')\n",
    "\n",
    "# 첫 시작 input 노드의 갯수가 21개, 다음 hidden 노드의 갯수는 128개\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, emb_size, input_length = 4)) # input 부분\n",
    "\n",
    "# 들어온 x에 대해서 한 행의 평균을 구해라\n",
    "model.add(tf.keras.layers.Lambda(lambda x : tf.reduce_mean(x, axis = 1)))\n",
    "\n",
    "# hidden 노드의 시작!\n",
    "model.add(tf.keras.layers.Dense(units = hidden_dimension, activation = 'relu', name = 'Dense1'))\n",
    "model.add(tf.keras.layers.Dense(units = output_dimension, activation = 'sigmoid', name = 'Outputs'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "068703ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6976 - acc: 0.3333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6792 - acc: 0.8333\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6504 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6340 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6148 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5925 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5674 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5366 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5011 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4617 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4163 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3696 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3194 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2709 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2246 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1821 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.7368e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.5078e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.2525e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.9912e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.7250e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.4737e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.2746e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.0638e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.8523e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.6676e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.4801e-04 - acc: 1.0000\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 7.2656e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.0931e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.9441e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.7663e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.6083e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.4495e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.3122e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.1605e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.0077e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.8879e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.7650e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.6278e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 939us/step - loss: 5.5143e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf86585f28>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "model.fit(input_sequence, targets, epochs = 100, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb9941",
   "metadata": {},
   "source": [
    "## Functional API 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "affafd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional API\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 4, 128)            2688      \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpL (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (4, ))\n",
    "embedding = tf.keras.layers.Embedding(vocab_size, emb_size, name = 'embedding')(inputs)\n",
    "lamda = tf.reduce_mean(embedding, axis = 1, name = 'lambda')\n",
    "hidden = tf.keras.layers.Dense(units = hidden_dimension, activation = 'relu', name = 'dense')(lamda)\n",
    "outputs = tf.keras.layers.Dense(units = 1, activation = 'sigmoid', name = 'outputs')(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'Functional API')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1b843c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model) :\n",
    "    def __init__(self, vocab_size, emb_size, hidden_dimension, output_dimension) :\n",
    "        super(CustomModel, self).__init__(name = 'Subclassing')\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_size, name = 'embedding')\n",
    "        self.dense = tf.keras.layers.Dense(units = hidden_dimension, activation = 'relu', name = 'dense')\n",
    "        self.outputs = tf.keras.layers.Dense(units = output_dimension, activation = 'sigmoid', name = 'outputs')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis = 1)\n",
    "        x = self.dense(x)\n",
    "        x = self.outputs(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "328ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = CustomModel(vocab_size, emb_size, hidden_dimension, output_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80d50c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6962 - acc: 0.3333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6758 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6606 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6435 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6251 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6069 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5837 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5581 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5281 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4920 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4533 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4104 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3643 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3175 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2708 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2253 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1847 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0933 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.7472e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.4592e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.2229e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.0015e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.7739e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.5552e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.3320e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.1453e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.9198e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.7315e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.5358e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.3803e-04 - acc: 1.0000\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 7.2029e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.0477e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.8871e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.7430e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.5856e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.4449e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.2836e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.1692e-04 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.0340e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.9193e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.7828e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.6604e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.5567e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf8666c7b8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['acc'])\n",
    "\n",
    "mymodel.fit(input_sequence, targets, epochs = 100, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc801aa",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "889bfb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-macosx_10_9_x86_64.whl (28.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8 MB 66.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "\u001b[K     |████████████████████████████████| 309 kB 88.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/kimhyunjo/opt/anaconda3/envs/nbkim/lib/python3.6/site-packages (from scikit-learn) (1.19.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.1 scikit-learn-0.24.2 scipy-1.5.4 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8224b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac87da",
   "metadata": {},
   "source": [
    "## iris 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f3a802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "699295ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "iris_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cb2dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d349430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c722d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(iris_dataset['data'])\n",
    "iris.columns = iris_dataset['feature_names']\n",
    "iris['target'] = iris_dataset['target']\n",
    "\n",
    "type(iris)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "908490fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "100                6.3               3.3                6.0               2.5   \n",
       "101                5.8               2.7                5.1               1.9   \n",
       "102                7.1               3.0                5.9               2.1   \n",
       "103                6.3               2.9                5.6               1.8   \n",
       "104                6.5               3.0                5.8               2.2   \n",
       "\n",
       "     target  \n",
       "100       2  \n",
       "101       2  \n",
       "102       2  \n",
       "103       2  \n",
       "104       2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setosa = iris[iris['target'] == 0]\n",
    "versicolor = iris[iris['target'] == 1]\n",
    "virgina = iris[iris['target'] == 2]\n",
    "\n",
    "virgina.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af2a5c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7faf8a55e358>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(setosa['sepal length (cm)'], setosa['sepal width (cm)'], marker = 'o', color = 'b', label = 'setosa')\n",
    "plt.scatter(versicolor['sepal length (cm)'], versicolor['sepal width (cm)'], marker = 'x', color = 'r', label = 'versicolor')\n",
    "plt.scatter(virgina['sepal length (cm)'], virgina['sepal width (cm)'], marker = 'v', color = 'm', label = 'virgina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adbe9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a97b27",
   "metadata": {},
   "source": [
    "### train, test data 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9176a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_label, test_label = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f21f88a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ce7fdfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9fbad",
   "metadata": {},
   "source": [
    "## StandardScaler 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6663c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f4c0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7fc2d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(train_scaled, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0709aa",
   "metadata": {},
   "source": [
    "### 신규 데이터 또한 StandardScaler 진행해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12ea4d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33066442, -0.55192639,  0.51683569,  1.32380572]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = np.array([[6.1, 2.8, 4.7, 2.2]])\n",
    "\n",
    "new_scaled = ss.transform(new_input)\n",
    "new_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bacd2bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.9, 0.1],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0.7, 0.3],\n",
       "       [0. , 0.8, 0.2]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label = knn.predict(new_scaled)\n",
    "predict_label\n",
    "\n",
    "# 주위에 있는 10개의 데이터 모두 2로 선택 되어 있다.\n",
    "knn.predict_proba(new_scaled)\n",
    "\n",
    "# test 용 데이터로 진행 했을 때는 값이 다르게 나오는것을 확인 할수 있다.\n",
    "knn.predict_proba(test_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a480968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predict_test = knn.predict(test_scaled)\n",
    "\n",
    "print(predict_test)\n",
    "\n",
    "print(np.mean(predict_test == test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e3dbd",
   "metadata": {},
   "source": [
    "# 비지도학습 k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "029b6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f9d91",
   "metadata": {},
   "source": [
    "### n_clusters 의 갯수는 하이퍼 파라미터다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "904fc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a583b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "train_input, test_input, train_label, test_label = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size = 0.25, random_state = 42)\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.fit_transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9970eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac3d82e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01827123  1.2864604  -1.39338902 -1.3621769 ]\n",
      " [-0.7730102   2.43545215 -1.33550342 -1.49647603]\n",
      " [-0.03722712 -0.78172474  0.74837808  0.92090833]\n",
      " [ 0.20803391  0.8268637   0.4010645   0.51801093]\n",
      " [ 1.06644751  0.13746866  0.51683569  0.3837118 ]\n",
      " [-0.52774918  1.97585545 -1.45127462 -1.09357864]\n",
      " [-0.52774918  1.51625875 -1.33550342 -1.3621769 ]\n",
      " [-0.40511866 -1.47111979 -0.06202028 -0.28778385]\n",
      " [ 0.57592545 -0.55192639  0.74837808  0.3837118 ]\n",
      " [ 0.69855596  0.13746866  0.97992047  0.7866092 ]\n",
      " [ 0.94381699 -0.09232969  0.3431789   0.24941267]\n",
      " [ 1.67960008  1.2864604   1.32723405  1.72670311]\n",
      " [-0.15985763 -0.32212804  0.2274077   0.11511354]\n",
      " [ 2.17012213 -0.09232969  1.61666204  1.18950659]\n",
      " [-0.28248815 -0.09232969  0.4010645   0.3837118 ]\n",
      " [-0.89564072  1.05666205 -1.39338902 -1.3621769 ]\n",
      " [ 2.29275265 -0.55192639  1.67454764  1.05520746]\n",
      " [-0.03722712 -0.78172474  0.16952211 -0.28778385]\n",
      " [-0.7730102   0.8268637  -1.39338902 -1.3621769 ]\n",
      " [-1.01827123  1.05666205 -1.45127462 -1.22787777]\n",
      " [-0.89564072  1.7460571  -1.10396103 -1.09357864]\n",
      " [-1.01827123 -2.39031318 -0.17779148 -0.28778385]\n",
      " [ 0.57592545 -0.78172474  0.63260689  0.7866092 ]\n",
      " [-1.26353226  0.8268637  -1.10396103 -1.3621769 ]\n",
      " [-1.01827123 -0.09232969 -1.27761783 -1.3621769 ]\n",
      " [-0.89564072  0.59706535 -1.21973223 -0.95927951]\n",
      " [-0.28248815 -0.78172474  0.2274077   0.11511354]\n",
      " [-0.89564072  0.8268637  -1.33550342 -1.3621769 ]\n",
      " [-0.15985763 -0.09232969  0.2274077  -0.01918559]\n",
      " [ 2.29275265  1.7460571   1.67454764  1.32380572]\n",
      " [-1.50879329  0.367267   -1.39338902 -1.3621769 ]\n",
      " [ 0.45329494 -0.32212804  0.2852933   0.11511354]\n",
      " [-0.15985763 -1.24132144  0.69049248  1.05520746]\n",
      " [-0.40511866  2.66525049 -1.39338902 -1.3621769 ]\n",
      " [ 0.20803391 -0.09232969  0.57472129  0.7866092 ]\n",
      " [-0.03722712 -0.78172474  0.74837808  0.92090833]\n",
      " [ 0.20803391 -1.93071649  0.11163651 -0.28778385]\n",
      " [-0.52774918 -0.09232969  0.4010645   0.3837118 ]\n",
      " [ 0.45329494  0.8268637   0.92203487  1.45810485]\n",
      " [-0.40511866 -1.70091814  0.11163651  0.11511354]\n",
      " [-0.52774918  1.97585545 -1.21973223 -1.09357864]\n",
      " [-1.01827123 -1.70091814 -0.29356267 -0.28778385]\n",
      " [ 0.69855596 -0.78172474  0.86414927  0.92090833]\n",
      " [-1.01827123  0.59706535 -1.39338902 -1.3621769 ]\n",
      " [-1.01827123  0.367267   -1.50916022 -1.3621769 ]\n",
      " [-0.40511866 -1.47111979 -0.00413469 -0.15348472]\n",
      " [ 1.06644751 -0.09232969  0.69049248  0.65231006]\n",
      " [-1.14090175  0.13746866 -1.33550342 -1.3621769 ]\n",
      " [-0.03722712 -0.55192639  0.74837808  1.59240398]\n",
      " [-1.01827123  0.8268637  -1.33550342 -1.3621769 ]\n",
      " [-1.01827123  1.05666205 -1.27761783 -0.82498038]\n",
      " [ 0.08540339  0.367267    0.57472129  0.7866092 ]\n",
      " [-0.89564072 -1.24132144 -0.46721946 -0.15348472]\n",
      " [ 1.31170853  0.367267    1.09569166  1.45810485]\n",
      " [ 0.20803391 -0.78172474  0.74837808  0.51801093]\n",
      " [ 0.33066442 -1.01152309  1.03780607  0.24941267]\n",
      " [ 2.29275265 -0.09232969  1.32723405  1.45810485]\n",
      " [-0.40511866 -1.24132144  0.11163651  0.11511354]\n",
      " [-1.75405432 -0.32212804 -1.39338902 -1.3621769 ]\n",
      " [-1.87668483 -0.09232969 -1.56704581 -1.49647603]\n",
      " [ 0.20803391 -1.93071649  0.69049248  0.3837118 ]\n",
      " [ 1.67960008  0.367267    1.26934846  0.7866092 ]\n",
      " [-1.50879329  0.13746866 -1.33550342 -1.3621769 ]\n",
      " [-0.89564072  1.05666205 -1.39338902 -1.22787777]\n",
      " [-1.75405432 -0.09232969 -1.45127462 -1.3621769 ]\n",
      " [ 0.57592545 -1.24132144  0.63260689  0.3837118 ]\n",
      " [ 0.57592545  0.8268637   1.03780607  1.59240398]\n",
      " [-1.50879329  0.8268637  -1.39338902 -1.22787777]\n",
      " [ 1.18907802 -0.09232969  0.97992047  1.18950659]\n",
      " [ 0.57592545  0.59706535  1.26934846  1.72670311]\n",
      " [-1.38616278  0.367267   -1.45127462 -1.3621769 ]\n",
      " [ 0.33066442 -0.32212804  0.51683569  0.24941267]\n",
      " [ 0.82118648 -0.55192639  0.45895009  0.3837118 ]\n",
      " [ 0.45329494 -0.55192639  0.57472129  0.7866092 ]\n",
      " [ 1.43433905  0.367267    0.51683569  0.24941267]\n",
      " [ 0.69855596  0.367267    0.86414927  1.45810485]\n",
      " [-0.89564072  1.7460571  -1.27761783 -1.3621769 ]\n",
      " [ 1.31170853  0.13746866  0.92203487  1.18950659]\n",
      " [ 0.08540339 -0.09232969  0.2274077   0.3837118 ]\n",
      " [ 0.82118648 -0.09232969  0.80626368  1.05520746]\n",
      " [-0.15985763 -1.01152309 -0.17779148 -0.28778385]\n",
      " [-0.7730102  -0.78172474  0.05375091  0.24941267]\n",
      " [ 0.33066442 -0.09232969  0.45895009  0.24941267]\n",
      " [-1.6314238  -1.70091814 -1.45127462 -1.22787777]\n",
      " [ 0.94381699 -0.32212804  0.45895009  0.11511354]\n",
      " [-0.40511866 -1.01152309  0.3431789  -0.01918559]\n",
      " [-0.65037969  1.51625875 -1.33550342 -1.3621769 ]\n",
      " [-0.28248815 -0.09232969  0.16952211  0.11511354]\n",
      " [ 1.80223059 -0.32212804  1.44300525  0.7866092 ]\n",
      " [ 1.06644751  0.59706535  1.09569166  1.18950659]\n",
      " [-0.89564072  1.51625875 -1.33550342 -1.09357864]\n",
      " [-1.14090175 -1.47111979 -0.29356267 -0.28778385]\n",
      " [ 1.06644751  0.59706535  1.09569166  1.72670311]\n",
      " [ 1.67960008 -0.09232969  1.15357726  0.51801093]\n",
      " [-1.14090175  1.2864604  -1.39338902 -1.49647603]\n",
      " [ 1.06644751  0.13746866  1.03780607  1.59240398]\n",
      " [-1.14090175 -0.09232969 -1.39338902 -1.3621769 ]\n",
      " [ 1.31170853  0.13746866  0.63260689  0.3837118 ]\n",
      " [ 1.9248611  -0.55192639  1.32723405  0.92090833]\n",
      " [ 0.57592545 -0.32212804  1.03780607  0.7866092 ]\n",
      " [-0.15985763 -0.55192639  0.16952211  0.11511354]\n",
      " [ 0.82118648 -0.09232969  0.97992047  0.7866092 ]\n",
      " [ 0.57592545 -1.70091814  0.3431789   0.11511354]\n",
      " [ 0.69855596 -0.32212804  0.2852933   0.11511354]\n",
      " [-0.28248815 -0.55192639  0.63260689  1.05520746]\n",
      " [ 0.08540339 -0.09232969  0.74837808  0.7866092 ]\n",
      " [-0.52774918  0.8268637  -1.21973223 -1.3621769 ]\n",
      " [ 0.33066442 -0.55192639  0.11163651  0.11511354]\n",
      " [-1.14090175 -1.24132144  0.4010645   0.65231006]\n",
      " [-0.03722712  2.2056538  -1.50916022 -1.3621769 ]\n",
      " [-0.03722712 -1.01152309  0.11163651 -0.01918559]\n",
      " [ 1.55696956 -0.09232969  1.21146286  1.18950659]]\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06e6008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0,\n",
       "       0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1,\n",
       "       2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 2], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1dfc78d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 1,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster = k_means.predict(test_scaled)\n",
    "predict_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f4852",
   "metadata": {},
   "source": [
    "#### 맞으면 True 틀리면 False 로 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b8c909c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_cluster == test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
